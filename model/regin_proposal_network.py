import numpy as np
from torch.nn import functional as F
import torch
from torch import nn
from model import creator

# from model.utils.bbox_tools import generate_anchor_base
# from model.utils.creator_tool import ProposalCreator


def generate_anchor_base(base_size=16, ratios=[0.5, 1, 2],anchor_scales=[8, 16, 32]):
    """Generate anchor base windows by enumerating aspect ratio and scales.

    生成以目标点为原点的9个base anchor框(都是相对坐标)

    Generate anchors that are scaled and modified to the given aspect ratios.
    Area of a scaled anchor is preserved when modifying to the given aspect
    ratio.

    :obj:`R = len(ratios) * len(anchor_scales)` anchors are generated by this
    function.
    The :obj:`i * len(anchor_scales) + j` th anchor corresponds to an anchor
    generated by :obj:`ratios[i]` and :obj:`anchor_scales[j]`.

    For example, if the scale is :math:`8` and the ratio is :math:`0.25`,
    the width and the height of the base window will be stretched by :math:`8`.
    For modifying the anchor to the given aspect ratio,
    the height is halved and the width is doubled.

    Args:
        base_size (number): The width and the height of the reference window.
        ratios (list of floats): This is ratios of width to height of
            the anchors.
        anchor_scales (list of numbers): This is areas of anchors.
            Those areas will be the product of the square of an element in
            :obj:`anchor_scales` and the original area of the reference
            window.

    Returns:
        ~numpy.ndarray:
        An array of shape :math:`(R, 4)`.
        Each element is a set of coordinates of a bounding box.
        The second axis corresponds to
        :math:`(y_{min}, x_{min}, y_{max}, x_{max})` of a bounding box.

    """
    py = base_size / 2.
    px = base_size / 2.

    anchor_base = np.zeros((len(ratios) * len(anchor_scales), 4),
                           dtype=np.float32)
    # print(ratios )
    for i in range(len(ratios)):
        for j in range(len(anchor_scales)):
            h = base_size * anchor_scales[j] * np.sqrt(ratios[i])
            w = base_size * anchor_scales[j] * np.sqrt(1. / ratios[i])

            index = i * len(anchor_scales) + j
            anchor_base[index, 0] = py - h / 2.
            anchor_base[index, 1] = px - w / 2.
            anchor_base[index, 2] = py + h / 2.
            anchor_base[index, 3] = px + w / 2.
    return anchor_base

class RegionProposalNetwork(nn.Module):
    """Region Proposal Network introduced in Faster R-CNN.

    RPN网络的作用：
        1.生成对所有anchor的位置和二分类预测(供训练)
        2.生成Region of Instrest(ROI) (供ROIhead网络进行位置回归和分类训练)

    This is Region Proposal Network introduced in Faster R-CNN [#]_.
    This takes features extracted from images and propose
    class agnostic bounding boxes around "objects".

    .. [#] Shaoqing Ren, Kaiming He, Ross Girshick, Jian Sun. \
    Faster R-CNN: Towards Real-Time Object Detection with \
    Region Proposal Networks. NIPS 2015.

    Args:
        in_channels (int): The channel size of input.
        mid_channels (int): The channel size of the intermediate tensor.
        ratios (list of floats): This is ratios of width to height of
            the anchors.
        anchor_scales (list of numbers): This is areas of anchors.
            Those areas will be the product of the square of an element in
            :obj:`anchor_scales` and the original area of the reference
            window.
        feat_stride (int): Stride size after extracting features from an
            image.
        initialW (callable): Initial weight value. If :obj:`None` then this
            function uses Gaussian distribution scaled by 0.1 to
            initialize weight.
            May also be a callable that takes an array and edits its values.
        proposal_creator_params (dict): Key valued paramters for
            :class:`model.utils.creator_tools.ProposalCreator`.

    .. seealso::
        :class:`~model.utils.creator_tools.ProposalCreator`

    """

    def __init__(self, in_channels=512, mid_channels=512, ratios=[0.5, 1, 2],anchor_scales=[8, 16, 32], feat_stride=16,
            proposal_creator_params=dict(),
    ):
        super(RegionProposalNetwork, self).__init__()
        # 生成面积为[128,256,512],比例为[0.5,1,2]的9个base anchor,[9,4]
        self.anchor_base = generate_anchor_base(base_size=16,anchor_scales=anchor_scales, ratios=ratios)
        self.feat_stride = feat_stride

        # proposal_layer用于生成ROI
        self.proposcal_creator = creator.ProposalCreator(self, **proposal_creator_params)
        n_anchor = self.anchor_base.shape[0]
        self.conv1 = nn.Conv2d(in_channels, mid_channels, 3, 1, 1)
        self.score = nn.Conv2d(mid_channels, n_anchor * 2, 1, 1, 0)
        self.loc = nn.Conv2d(mid_channels, n_anchor * 4, 1, 1, 0)
        self.normal_init(self.conv1, 0, 0.01)
        self.normal_init(self.score, 0, 0.01)
        self.normal_init(self.loc, 0, 0.01)

    def forward(self, x, img_size, scale=1.):
        """Forward Region Proposal Network.

        Here are notations.

        * :math:`N` is batch size.
        * :math:`C` channel size of the input.
        * :math:`H` and :math:`W` are height and witdh of the input feature.
        * :math:`A` is number of anchors assigned to each pixel.

        Args:
            x (~torch.autograd.Variable): The Features extracted from images.
                Its shape is :math:`(N, C, H, W)`.
            img_size (tuple of ints): A tuple :obj:`height, width`,
                which contains image size after scaling.
            scale (float): The amount of scaling done to the input images after
                reading them from files.

        Returns:
            (~torch.autograd.Variable, ~torch.autograd.Variable, array, array, array):

            This is a tuple of five following values.

            * **rpn_locs**: Predicted bounding box offsets and scales for \
                anchors. Its shape is :math:`(N, H W A, 4)`.
            * **rpn_scores**:  Predicted foreground scores for \
                anchors. Its shape is :math:`(N, H W A, 2)`.
            * **rois**: A bounding box array containing coordinates of \
                proposal boxes.  This is a concatenation of bounding box \
                arrays from multiple images in the batch. \
                Its shape is :math:`(R', 4)`. Given :math:`R_i` predicted \
                bounding boxes from the :math:`i` th image, \
                :math:`R' = \\sum _{i=1} ^ N R_i`.
            * **roi_indices**: An array containing indices of images to \
                which RoIs correspond to. Its shape is :math:`(R',)`.
            * **anchor**: Coordinates of enumerated shifted anchors. \
                Its shape is :math:`(H W A, 4)`.

        """

        # 这里的x是通过extractor提取出的feature_map
        # n这里只支持=1
        # x:[1,in_channel=512,hh,ww]
        n, _, hh, ww = x.shape
        # 枚举出feature_map上每个点对应原图的anchor，这里的原图是指transform之后的图像
        # anchor:[hh*ww*9,4]
        anchor = self._enumerate_shifted_anchor(np.array(self.anchor_base),self.feat_stride, hh, ww)

        n_anchor = anchor.shape[0] // (hh * ww)     # len(ratios)*len(anchor_scales)=9
        # 按照原文的说法,这里再做一次卷积,3*3的卷积不会改变feature_map的大小,所以上面计算出的所有anchor依然适用
        # 猜测这样做的目的：使得原始feature上每个3*3的框对应原图的9个anchor,增强鲁棒性？
        # h:[1,mid_channel=512,hh,ww]
        h = F.relu(self.conv1(x))

        # 获得每个anchor的四个修正量,即loc
        # rpn_locs:[1,9*4,hh,ww], 经过reshape之后,[1,9*hh*ww,4],9*hh*ww代表anchor的数量
        rpn_locs = self.loc(h)
        rpn_locs = rpn_locs.permute(0, 2, 3, 1).contiguous().view(n, -1, 4)

        # 获得每个anchor的打分,这里为一个前景后景二分类,即是物体或不是物体
        # 这里为什么不只生成一个分数
        rpn_scores = self.score(h)
        rpn_scores = rpn_scores.permute(0, 2, 3, 1).contiguous()
        rpn_scores = rpn_scores.view(n, hh, ww, n_anchor, 2)
        rpn_fg_scores = rpn_scores[:, :, :, :, 1].contiguous()
        # 前景(是物体)概率:[1,hh,ww,9]
        rpn_fg_scores = rpn_fg_scores.view(n, -1)
        # 二分类概率:[1,9*hh*ww,2]
        rpn_scores = rpn_scores.view(n, -1, 2)

        # 这里n=1,所以只选取[0]
        # 通过proposcal_creator,根据IOU选取ROI
        # 这里rpn_locs是[dx1,dy1,dx2,dy2],在proposcal_creator内会根据archor转化成bbox
        # 这里的roi就是bbox通过筛选的结果[num_post_nms,4],是[x1,y1,x2,y2的形式]
        roi = self.proposcal_creator(rpn_locs[0].cpu().data.numpy(),rpn_fg_scores[0].cpu().data.numpy(),anchor, img_size,scale=scale)

        # batch_index = i * np.ones((len(roi),), dtype=np.int32)
        # rois.append(roi)
        # roi_indices.append(batch_index)
        #
        # # 这里的batch_index是[0,0...0,0]???
        # # -解答-：全0是因为只支持batch size=1,这个index相当于在batch里的索引,如果batch size=2,这里就为[[0,0..,0],[1,1..,1]]
        # rois = np.concatenate(rois, axis=0)
        # roi_indices = np.concatenate(roi_indices, axis=0)

        # 注意,这里对每个anchor都进行了位置和分类的预测，也就是对9*hh*ww个anchor都进行了预测
        return rpn_locs, rpn_scores, roi, anchor


    def _enumerate_shifted_anchor(self,anchor_base, feat_stride, height, width):
        # Enumerate all shifted anchors:
        #
        # add A anchors (1, A, 4) to
        # cell K shifts (K, 1, 4) to get
        # shift anchors (K, A, 4)
        # reshape to (K*A, 4) shifted anchors
        # return (K*A, 4)

        # !TODO: add support for torch.CudaTensor
        # xp = cuda.get_array_module(anchor_base)
        # it seems that it can't be boosed using GPU
        import numpy as xp
        shift_y = xp.arange(0, height * feat_stride, feat_stride)
        shift_x = xp.arange(0, width * feat_stride, feat_stride)
        shift_x, shift_y = xp.meshgrid(shift_x, shift_y)
        shift = xp.stack((shift_y.ravel(), shift_x.ravel(),
                          shift_y.ravel(), shift_x.ravel()), axis=1)

        A = anchor_base.shape[0]
        K = shift.shape[0]
        anchor = anchor_base.reshape((1, A, 4)) + \
                 shift.reshape((1, K, 4)).transpose((1, 0, 2))
        anchor = anchor.reshape((K * A, 4)).astype(np.float32)
        return anchor


    def normal_init(self,m, mean, stddev, truncated=False):
        """
        weight initalizer: truncated normal and random normal.
        """
        # x is a parameter
        if truncated:
            m.weight.data.normal_().fmod_(2).mul_(stddev).add_(mean)  # not a perfect approximation
        else:
            m.weight.data.normal_(mean, stddev)
            m.bias.data.zero_()

if __name__ == '__main__':
    pass
